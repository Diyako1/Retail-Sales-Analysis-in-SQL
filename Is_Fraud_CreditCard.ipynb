{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1798190c-881a-4e31-b441-44129b384341",
   "metadata": {},
   "source": [
    "# Diyako Gilibagu (2024): This project uses a Kaggle dataset of credit card transactions by European cardholders in 2013 to build machine learning models for fraud detection, focusing on imbalanced data with PCA-transformed features and a binary fraud label.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06798def-1cdb-44b6-938a-a66eda75f557",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas numpy scikit-learn tensorflow matplotlib seaborn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1f83e4-2b52-47bd-b13c-45faab0e7ccb",
   "metadata": {},
   "source": [
    "# Preprocessing Data for Easier Use Later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e47072-03b7-4120-ad2e-72734c79cb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import RobustScaler from sklearn to scale features while reducing the influence of outliers.\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "# Copy the original dataset for processing\n",
    "new_data = data.copy()\n",
    "\n",
    "# Scale the 'Amount' feature using RobustScaler\n",
    "new_data['Amount'] = RobustScaler().fit_transform(new_data['Amount'].to_numpy().reshape(-1, 1))\n",
    "\n",
    "# Display histogram and stats for 'Amount'\n",
    "new_data['Amount'].hist()\n",
    "print(new_data['Amount'].describe())\n",
    "\n",
    "# Normalize the 'Time' column\n",
    "time = new_data['Time']\n",
    "new_data['Time'] = (time - time.min()) / (time.max() - time.min())\n",
    "\n",
    "# Shuffle the entire dataset randomly\n",
    "new_data = new_data.sample(frac=1, random_state=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e516867-2054-43e1-8bfb-7a0a53b19bca",
   "metadata": {},
   "source": [
    "# Splitting Data for Training, Testing, and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789eda4f-5695-4a76-91da-db1bd103d866",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the shuffled data into training, testing, and validation sets\n",
    "train, test, val = new_data[:240000], new_data[240000:262000], new_data[262000:]\n",
    "\n",
    "# Print the class distribution (fraud vs non-fraud) in each set\n",
    "print(train['Class'].value_counts())\n",
    "print(test['Class'].value_counts())\n",
    "print(val['Class'].value_counts())\n",
    "\n",
    "# Convert the DataFrames into numpy arrays for model compatibility\n",
    "train_np, test_np, val_np = train.to_numpy(), test.to_numpy(), val.to_numpy()\n",
    "\n",
    "# Split into input and output\n",
    "x_train, y_train = train_np[:, :-1], train_np[:, -1]\n",
    "x_test, y_test = test_np[:, :-1], test_np[:, -1]\n",
    "x_val, y_val = val_np[:, :-1], val_np[:, -1]\n",
    "\n",
    "# Print the shapes of datasets\n",
    "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape, x_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad84564f-8112-483e-9e82-9b76d532af30",
   "metadata": {},
   "source": [
    "# Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32746f15-3a51-4e89-8163-3f39c3e8bf4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9992375\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Not Fraud       1.00      1.00      1.00     22771\n",
      "       Fraud       0.83      0.56      0.67        36\n",
      "\n",
      "    accuracy                           1.00     22807\n",
      "   macro avg       0.92      0.78      0.83     22807\n",
      "weighted avg       1.00      1.00      1.00     22807\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Train the logistic regression model\n",
    "logistic_model = LogisticRegression()\n",
    "logistic_model.fit(x_train, y_train)\n",
    "\n",
    "# Print training accuracy\n",
    "print(logistic_model.score(x_train, y_train))\n",
    "\n",
    "# Evaluate model on validation set\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Define target names for the classification report\n",
    "target_names = ['Not Fraud', 'Fraud']\n",
    "\n",
    "# Generate and print the classification report\n",
    "print(classification_report(y_val, logistic_model.predict(x_val), target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd2b0f4-9d27-46f5-bb00-27808812a560",
   "metadata": {},
   "source": [
    "# Shallow Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4812a0-4175-4186-a66f-79430337cb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import InputLayer, Dense, BatchNormalization\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# Define the neural network\n",
    "shallow_nn = Sequential([\n",
    "    InputLayer((x_train.shape[1],)),\n",
    "    Dense(2, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dense(1, activation='sigmoid')  # Sigmoid for binary classification\n",
    "])\n",
    "\n",
    "# Define a checkpoint to save the best model\n",
    "checkpoint = ModelCheckpoint('shallow_nn.keras', save_best_only=True)\n",
    "\n",
    "# Compile the neural network\n",
    "shallow_nn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print the model summary\n",
    "#shallow_nn.summary()\n",
    "\n",
    "# Train the neural network\n",
    "shallow_nn.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=5, callbacks=[checkpoint])\n",
    "\n",
    "# Define a function to generate predictions\n",
    "def neural_net_predictions(model, x):\n",
    "    return (model.predict(x).flatten() > 0.5).astype(int)\n",
    "\n",
    "# Generate predictions for the validation set\n",
    "predictions = neural_net_predictions(shallow_nn, x_val)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ad116b2-61b3-44d0-8733-414e37ddb50f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Not Fraud       1.00      1.00      1.00     22771\n",
      "       Fraud       0.67      0.78      0.72        36\n",
      "\n",
      "    accuracy                           1.00     22807\n",
      "   macro avg       0.83      0.89      0.86     22807\n",
      "weighted avg       1.00      1.00      1.00     22807\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate neural network on validation data\n",
    "print(classification_report(y_val, predictions, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5a8f21-a29f-40e3-b942-7972e10d0ff9",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01ce65a8-94a6-4336-9fc8-cfd9399356a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Not Fraud       1.00      1.00      1.00     22771\n",
      "       Fraud       0.80      0.44      0.57        36\n",
      "\n",
      "    accuracy                           1.00     22807\n",
      "   macro avg       0.90      0.72      0.79     22807\n",
      "weighted avg       1.00      1.00      1.00     22807\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(max_depth=2, n_jobs=1)\n",
    "rf.fit(x_train, y_train)\n",
    "print(classification_report(y_val, rf.predict(x_val), target_names=target_names))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c728f9e-04cf-4afe-b22e-99485900d526",
   "metadata": {},
   "source": [
    "# Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81f7fe11-0557-4324-b2d7-5fa4107d5a75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Not Fraud       1.00      1.00      1.00     22771\n",
      "       Fraud       0.67      0.67      0.67        36\n",
      "\n",
      "    accuracy                           1.00     22807\n",
      "   macro avg       0.83      0.83      0.83     22807\n",
      "weighted avg       1.00      1.00      1.00     22807\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gbc = GradientBoostingClassifier(n_estimators=50, learning_rate=1.0, max_depth=1, random_state=0)\n",
    "gbc.fit(x_train, y_train)\n",
    "print(classification_report(y_val, gbc.predict(x_val), target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7894816-c32d-4d0c-acaf-8431b408028e",
   "metadata": {},
   "source": [
    "# Linear Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "260489b2-9f82-4a15-ac3b-f63b022c00c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Not Fraud       1.00      0.98      0.99     22771\n",
      "       Fraud       0.07      0.97      0.14        36\n",
      "\n",
      "    accuracy                           0.98     22807\n",
      "   macro avg       0.54      0.98      0.56     22807\n",
      "weighted avg       1.00      0.98      0.99     22807\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "svc = LinearSVC(class_weight='balanced')\n",
    "svc.fit(x_train, y_train)\n",
    "print(classification_report(y_val, svc.predict(x_val), target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bfca9f5-012f-4b70-837f-9664a45a33e6",
   "metadata": {},
   "source": [
    "# Balancing the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1614327e-3642-4052-bb50-e06deeca14f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "not_frauds = new_data.query('Class == 0')\n",
    "frauds = new_data.query('Class == 1')\n",
    "print(not_frauds['Class'].value_counts(), frauds['Class'].value_counts())\n",
    "\n",
    "balanced_data = pd.concat([frauds, not_frauds.sample(len(frauds), random_state=1)])\n",
    "print(balanced_data['Class'].value_counts())\n",
    "\n",
    "balanced_data = balanced_data.sample(frac=1, random_state=1)\n",
    "balanced_data_np = balanced_data.to_numpy()\n",
    "\n",
    "x_train_b, y_train_b = balanced_data_np[:700, :-1], balanced_data_np[:700, -1]\n",
    "x_test_b, y_test_b = balanced_data_np[700:842, :-1], balanced_data_np[700:842, -1]\n",
    "x_val_b, y_val_b = balanced_data_np[842:, :-1], balanced_data_np[842:, -1]\n",
    "\n",
    "print(x_train_b.shape, y_train_b.shape, x_test_b.shape, y_test_b.shape, x_val_b.shape, y_val_b.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d4eeb2-4486-484a-b354-9d70322ca509",
   "metadata": {},
   "source": [
    "# Linear Support Vector Classifier (Balanced Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d4d46842-340c-4710-9067-10f535624876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Not Fraud       0.96      0.93      0.94        72\n",
      "       Fraud       0.93      0.96      0.94        70\n",
      "\n",
      "    accuracy                           0.94       142\n",
      "   macro avg       0.94      0.94      0.94       142\n",
      "weighted avg       0.94      0.94      0.94       142\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svc_b = LinearSVC(class_weight='balanced')\n",
    "svc_b.fit(x_train_b, y_train_b)\n",
    "print(classification_report(y_val_b, svc_b.predict(x_val_b), target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d491fce6-6b85-4128-9eb0-61b4f78f8270",
   "metadata": {},
   "source": [
    "# Random Forest (Balanced Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4a448d75-a7a5-4cf1-b67a-26d8a25f0a18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Not Fraud       0.93      0.97      0.95        72\n",
      "       Fraud       0.97      0.93      0.95        70\n",
      "\n",
      "    accuracy                           0.95       142\n",
      "   macro avg       0.95      0.95      0.95       142\n",
      "weighted avg       0.95      0.95      0.95       142\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_b = RandomForestClassifier(max_depth=2, n_jobs=1)\n",
    "rf_b.fit(x_train_b, y_train_b)\n",
    "print(classification_report(y_val_b, rf_b.predict(x_val_b), target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e371db-d648-4f95-829f-4e4ed546d926",
   "metadata": {},
   "source": [
    "# Gradient Boosting Classifier (Balanced Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cd8c2a00-bc75-4b4a-b92d-0f286f1647de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Not Fraud       0.98      0.86      0.92        72\n",
      "       Fraud       0.87      0.99      0.93        70\n",
      "\n",
      "    accuracy                           0.92       142\n",
      "   macro avg       0.93      0.92      0.92       142\n",
      "weighted avg       0.93      0.92      0.92       142\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gbc_b = GradientBoostingClassifier(n_estimators=50, learning_rate=1.0, max_depth=1, random_state=0)\n",
    "gbc_b.fit(x_train_b, y_train_b)\n",
    "print(classification_report(y_val_b, gbc_b.predict(x_val_b), target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b235f8-75dd-4daa-b57e-392c2afd4df0",
   "metadata": {},
   "source": [
    "# Logistic Regression Model (Balanced Data set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316f358b-a383-4d5e-8317-2334dce68974",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_val_b, logistic_model.predict(x_val_b), target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd184bf3-bc52-46b7-a636-6a13810fd2cd",
   "metadata": {},
   "source": [
    "# Shallow Neural Network (Balanced Data set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82576959-c06e-4c33-a021-1afc49a1c3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "shallow_nn_b = Sequential()\n",
    "shallow_nn_b.add(InputLayer((x_train.shape[1],)))\n",
    "shallow_nn_b.add(Dense(2, activation='relu'))\n",
    "shallow_nn_b.add(BatchNormalization())\n",
    "shallow_nn_b.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "checkpoint = ModelCheckpoint('shallow_nn_b.keras', save_best_only=True)\n",
    "shallow_nn_b.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "shallow_nn_b.fit(x_train_b, y_train_b, validation_data=(x_val_b, y_val_b), epochs=40, callbacks=[checkpoint])\n",
    "\n",
    "# Evaluate Neural Network on Validation Data\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "shallow_nn_b = load_model('shallow_nn_b.keras')\n",
    "\n",
    "def neural_net_predictions(model, data):\n",
    "    return (model.predict(data) > 0.5).astype(\"int32\")\n",
    "\n",
    "print(classification_report(y_val_b, neural_net_predictions(shallow_nn_b, x_val_b), target_names=target_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a646a455-7e19-44fe-b9cd-93df1331c580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Not Fraud       0.96      0.90      0.93        72\n",
      "       Fraud       0.91      0.96      0.93        70\n",
      "\n",
      "    accuracy                           0.93       142\n",
      "   macro avg       0.93      0.93      0.93       142\n",
      "weighted avg       0.93      0.93      0.93       142\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_val_b, neural_net_predictions(shallow_nn_b, x_val_b), target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52851f4-b0d6-4c93-9698-81038160e956",
   "metadata": {},
   "source": [
    "# Test Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6389b67e-22e7-4ab1-9f3b-b6d596d59940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Not Fraud       0.91      0.84      0.87        73\n",
      "       Fraud       0.84      0.91      0.88        69\n",
      "\n",
      "    accuracy                           0.87       142\n",
      "   macro avg       0.88      0.87      0.87       142\n",
      "weighted avg       0.88      0.87      0.87       142\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_b, neural_net_predictions(shallow_nn_b, x_test_b), target_names=target_names))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Test",
   "language": "python",
   "name": "test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
